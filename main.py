#!/usr/bin/env python3
"""
QUIC pcap íŒŒì¼ ë¶„ì„ ë° í†µê³„ ìƒì„± ë„êµ¬
ê° QUIC flowì˜ ì „ì²´ í†µê³„ì™€ ì²« 5, 10, 15, 20ê°œ íŒ¨í‚·ì— ëŒ€í•œ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
tsharkë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥¸ ì²˜ë¦¬.
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
import pandas as pd
from collections import defaultdict
from tqdm import tqdm
import time
import subprocess

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ì„¤ì •
PCAP_ROOT_DIR = Path(os.getenv("PCAP_ROOT_DIR", "/Volumes/Lieutenant/quic"))
OUTPUT_DIR = Path("output")
PACKET_WINDOWS = [5, 10, 15, 20]  # ë¶„ì„í•  íŒ¨í‚· ê°œìˆ˜

# ì¶œë ¥ í´ë” êµ¬ì¡°
OUTPUT_FOLDERS = {
    'full': OUTPUT_DIR / 'full',
    5: OUTPUT_DIR / '5',
    10: OUTPUT_DIR / '10',
    15: OUTPUT_DIR / '15',
    20: OUTPUT_DIR / '20',
}


def setup_output_directories():
    """ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    for folder in OUTPUT_FOLDERS.values():
        folder.mkdir(parents=True, exist_ok=True)


def find_first_pcap_in_folders(root_dir: Path) -> List[Path]:
    """
    ëª¨ë“  í´ë”(ì¬ê·€ì )ì—ì„œ ì²« ë²ˆì§¸ pcap íŒŒì¼ì„ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        root_dir: pcap íŒŒì¼ë“¤ì´ ìˆëŠ” ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        
    Returns:
        ê° í´ë”ì˜ ì²« ë²ˆì§¸ pcap íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    pcap_files = []
    visited_dirs = set()
    
    if not root_dir.exists():
        print(f"ê²½ê³ : {root_dir} ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return pcap_files
    
    def find_pcaps_recursive(directory: Path):
        """ì¬ê·€ì ìœ¼ë¡œ ê° í´ë”ì˜ ì²« ë²ˆì§¸ pcap íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
        if directory in visited_dirs:
            return
        visited_dirs.add(directory)
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì°¾ì€ pcap íŒŒì¼ë“¤
        direct_pcaps = sorted([f for f in directory.glob("*.pcap") if f.is_file()])
        
        if direct_pcaps:
            # í˜„ì¬ ë””ë ‰í† ë¦¬ì— pcap íŒŒì¼ì´ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ íŒŒì¼ë§Œ ì¶”ê°€
            pcap_files.append(direct_pcaps[0])
        else:
            # í˜„ì¬ ë””ë ‰í† ë¦¬ì— pcapì´ ì—†ìœ¼ë©´ ì„œë¸Œë””ë ‰í† ë¦¬ íƒìƒ‰
            subdirs = sorted([d for d in directory.iterdir() if d.is_dir()])
            for subdir in subdirs:
                find_pcaps_recursive(subdir)
    
    # ë£¨íŠ¸ì˜ ì§ì ‘ ì„œë¸Œë””ë ‰í† ë¦¬ë“¤ì„ ìˆœíšŒ
    subdirs = sorted([d for d in root_dir.iterdir() if d.is_dir()])
    for subdir in subdirs:
        find_pcaps_recursive(subdir)
    
    return pcap_files


def format_file_size(size_bytes: int) -> str:
    """
    íŒŒì¼ í¬ê¸°ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        size_bytes: ë°”ì´íŠ¸ ë‹¨ìœ„ í¬ê¸°
        
    Returns:
        í¬ë§·ëœ ë¬¸ìì—´ (ì˜ˆ: "1.5 MB")
    """
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f} PB"


def extract_quic_flows_tshark(pcap_file: Path) -> Dict[str, List[Dict[str, Any]]]:
    """
    tsharkë¥¼ ì‚¬ìš©í•˜ì—¬ pcap íŒŒì¼ì—ì„œ QUIC flowë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í…ìŠ¤íŠ¸ í•„ë“œ ì¶œë ¥ ëª¨ë“œ ì‚¬ìš© (JSONë³´ë‹¤ ë¹ ë¥´ê³  ì•ˆì •ì )
    
    Args:
        pcap_file: ë¶„ì„í•  pcap íŒŒì¼ ê²½ë¡œ
        
    Returns:
        flow_idë¥¼ í‚¤ë¡œ í•˜ëŠ” íŒ¨í‚· ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    flows: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
    
    file_size = pcap_file.stat().st_size
    file_size_str = format_file_size(file_size)
    
    print(f"  ğŸ“– íŒŒì¼ ì½ê¸°: {pcap_file.name} ({file_size_str})")
    
    try:
        # tshark ëª…ë ¹ì–´ - í…ìŠ¤íŠ¸ í•„ë“œ ì¶œë ¥ ëª¨ë“œ (ë” ë¹ ë¥´ê³  ì•ˆì •ì )
        # -T fields: í•„ë“œ í…ìŠ¤íŠ¸ ì¶œë ¥
        # -E separator=,: CSV í˜•ì‹
        # -E quote=d: í°ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸°
        cmd = [
            'tshark',
            '-r', str(pcap_file),
            '-Y', 'quic || udp.port == 443',
            '-T', 'fields',
            '-E', 'separator=,',
            '-E', 'quote=d',
            '-e', 'ip.src',
            '-e', 'ip.dst',
            '-e', 'ipv6.src',
            '-e', 'ipv6.dst',
            '-e', 'udp.srcport',
            '-e', 'udp.dstport',
            '-e', 'frame.len',
            '-e', 'frame.time_epoch'
        ]
        
        # tshark ì‹¤í–‰
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=True
        )
        
        # ì¶œë ¥ íŒŒì‹±
        lines = result.stdout.strip().split('\n')
        
        with tqdm(total=len(lines), desc="  íŒ¨í‚· ì²˜ë¦¬", unit="pkt", leave=False) as pbar:
            for line in lines:
                if not line.strip():
                    continue
                
                # CSV íŒŒì‹± (ë”°ì˜´í‘œ ì œê±°)
                fields = [f.strip('"').strip() for f in line.split(',')]
                
                if len(fields) < 8:
                    pbar.update(1)
                    continue
                
                # í•„ë“œ ì¶”ì¶œ
                ip_src = fields[0]
                ip_dst = fields[1]
                ipv6_src = fields[2]
                ipv6_dst = fields[3]
                src_port = fields[4]
                dst_port = fields[5]
                frame_len = fields[6]
                time_epoch = fields[7]
                
                # IP ì£¼ì†Œ ê²°ì • (IPv4 ìš°ì„ , ì—†ìœ¼ë©´ IPv6)
                src_ip = ip_src if ip_src else ipv6_src
                dst_ip = ip_dst if ip_dst else ipv6_dst
                
                # í•„ìˆ˜ í•„ë“œ ì²´í¬
                if not src_ip or not dst_ip or not src_port or not dst_port:
                    pbar.update(1)
                    continue
                
                # íŒ¨í‚· ì •ë³´ ìƒì„±
                try:
                    packet_info = {
                        'src_ip': src_ip,
                        'dst_ip': dst_ip,
                        'src_port': src_port,
                        'dst_port': dst_port,
                        'size': int(frame_len) if frame_len else 0,
                        'timestamp': float(time_epoch) if time_epoch else 0.0
                    }
                except (ValueError, TypeError):
                    pbar.update(1)
                    continue
                
                # Flow ID ìƒì„± (ì–‘ë°©í–¥ í†µí•©)
                flow_id_1 = f"{src_ip}:{src_port}->{dst_ip}:{dst_port}"
                flow_id_2 = f"{dst_ip}:{dst_port}->{src_ip}:{src_port}"
                flow_id = min(flow_id_1, flow_id_2)
                
                # Flowì— íŒ¨í‚· ì¶”ê°€
                flows[flow_id].append(packet_info)
                
                pbar.update(1)
        
        print(f"  âœ“ {len(flows)}ê°œ flow, {len(lines)}ê°œ íŒ¨í‚· ë°œê²¬")
        
    except subprocess.CalledProcessError as e:
        print(f"  âŒ tshark ì‹¤í–‰ ì˜¤ë¥˜: {e.stderr}")
        raise
    except Exception as e:
        print(f"  âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise
    
    return flows


def calculate_packet_statistics(packets: List[Dict[str, Any]], num_packets: int = None) -> Dict[str, Any]:
    """
    íŒ¨í‚·ë“¤ì˜ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        packets: íŒ¨í‚· ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        num_packets: ë¶„ì„í•  íŒ¨í‚· ê°œìˆ˜ (Noneì´ë©´ ì „ì²´)
        
    Returns:
        í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    if num_packets:
        packets = packets[:num_packets]
    
    if not packets:
        return {}
    
    stats = {
        'packet_count': len(packets),
        'total_bytes': 0,
        'avg_packet_size': 0,
        'min_packet_size': float('inf'),
        'max_packet_size': 0,
        'duration': 0,
    }
    
    packet_sizes = []
    timestamps = []
    
    for packet_info in packets:
        try:
            # íŒ¨í‚· í¬ê¸°
            size = packet_info.get('size', 0)
            if size > 0:
                packet_sizes.append(size)
                stats['total_bytes'] += size
                stats['min_packet_size'] = min(stats['min_packet_size'], size)
                stats['max_packet_size'] = max(stats['max_packet_size'], size)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„
            timestamp = packet_info.get('timestamp', 0)
            if timestamp > 0:
                timestamps.append(timestamp)
                
        except Exception:
            continue
    
    # í‰ê·  ê³„ì‚°
    if packet_sizes:
        stats['avg_packet_size'] = sum(packet_sizes) / len(packet_sizes)
    
    # Duration ê³„ì‚°
    if len(timestamps) >= 2:
        stats['duration'] = timestamps[-1] - timestamps[0]
    
    # ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬
    if stats['min_packet_size'] == float('inf'):
        stats['min_packet_size'] = 0
    
    return stats


def analyze_pcap_file(pcap_file: Path) -> Dict[str, int]:
    """
    pcap íŒŒì¼ì„ ë¶„ì„í•˜ê³  ê° ì¢…ë¥˜ë³„ë¡œ CSVë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        pcap_file: ë¶„ì„í•  pcap íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì²˜ë¦¬ëœ flow ê°œìˆ˜ ë”•ì…”ë„ˆë¦¬
    """
    start_time = time.time()
    
    try:
        # QUIC flow ì¶”ì¶œ
        flows = extract_quic_flows_tshark(pcap_file)
        
        if not flows:
            print(f"  âš ï¸  flow ì—†ìŒ")
            return {'full': 0, 5: 0, 10: 0, 15: 0, 20: 0}
        
        filename_base = pcap_file.stem
        
        # ì „ì²´ flow í†µê³„ ê³„ì‚°
        print(f"  âš™ï¸  ì „ì²´ í†µê³„ ê³„ì‚° ì¤‘...")
        full_results = []
        for flow_id, packets in tqdm(flows.items(), desc="  ì „ì²´ flow", leave=False):
            flow_result = {
                'file': pcap_file.name,
                'flow_id': flow_id,
                'total_packets': len(packets),
            }
            
            # ì „ì²´ flow í†µê³„
            full_stats = calculate_packet_statistics(packets)
            for key, value in full_stats.items():
                flow_result[key] = value
            
            full_results.append(flow_result)
        
        # ì „ì²´ í†µê³„ ì €ì¥
        if full_results:
            df = pd.DataFrame(full_results)
            output_path = OUTPUT_FOLDERS['full'] / f"{filename_base}.csv"
            df.to_csv(output_path, index=False)
        
        # ê° ìœˆë„ìš° í¬ê¸°ë³„ë¡œ í†µê³„ ê³„ì‚°
        window_counts = {5: 0, 10: 0, 15: 0, 20: 0}
        
        for window in PACKET_WINDOWS:
            print(f"  âš™ï¸  ì²« {window}ê°œ íŒ¨í‚· í†µê³„ ê³„ì‚° ì¤‘...")
            window_results = []
            
            for flow_id, packets in tqdm(flows.items(), desc=f"  ì²« {window}ê°œ", leave=False):
                if len(packets) < window:
                    continue
                
                flow_result = {
                    'file': pcap_file.name,
                    'flow_id': flow_id,
                    'window_size': window,
                    'total_packets_in_flow': len(packets),
                }
                
                # ì²« Nê°œ íŒ¨í‚· í†µê³„
                window_stats = calculate_packet_statistics(packets, window)
                for key, value in window_stats.items():
                    flow_result[key] = value
                
                window_results.append(flow_result)
                window_counts[window] += 1
            
            # ìœˆë„ìš°ë³„ í†µê³„ ì €ì¥
            if window_results:
                df = pd.DataFrame(window_results)
                output_path = OUTPUT_FOLDERS[window] / f"{filename_base}.csv"
                df.to_csv(output_path, index=False)
        
        elapsed = time.time() - start_time
        print(f"  âœ“ ì™„ë£Œ: {len(flows)} flows, {elapsed:.2f}ì´ˆ")
        
        return {'full': len(full_results), **window_counts}
        
    except Exception as e:
        print(f"  âŒ ì˜¤ë¥˜: {str(e)}")
        return {'full': 0, 5: 0, 10: 0, 15: 0, 20: 0}


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 80)
    print("QUIC pcap íŒŒì¼ ë¶„ì„ ì‹œì‘ (tshark ì§ì ‘ ì‚¬ìš©)")
    print(f"PCAP ë£¨íŠ¸ ë””ë ‰í† ë¦¬: {PCAP_ROOT_DIR}")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}")
    print("=" * 80)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    setup_output_directories()
    print("âœ“ ì¶œë ¥ í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ")
    
    # ê° í´ë”ì—ì„œ ì²« ë²ˆì§¸ pcap íŒŒì¼ ì°¾ê¸°
    pcap_files = find_first_pcap_in_folders(PCAP_ROOT_DIR)
    
    if not pcap_files:
        print("âŒ ë¶„ì„í•  pcap íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ“ {len(pcap_files)}ê°œì˜ pcap íŒŒì¼ ë°œê²¬")
    for pcap_file in pcap_files:
        print(f"  - {pcap_file.relative_to(PCAP_ROOT_DIR)}")
    
    print("\n" + "=" * 80)
    print("ë¶„ì„ ì‹œì‘...")
    print("=" * 80 + "\n")
    
    # ì „ì²´ ì§„í–‰ ìƒí™©ì„ ìœ„í•œ ì¹´ìš´í„°
    total_stats = {
        'full': 0,
        5: 0,
        10: 0,
        15: 0,
        20: 0
    }
    
    # ì§„í–‰ í‘œì‹œì¤„ê³¼ í•¨ê»˜ íŒŒì¼ ì²˜ë¦¬
    for i, pcap_file in enumerate(pcap_files, 1):
        print(f"\n[{i}/{len(pcap_files)}] {pcap_file.name}")
        print("-" * 80)
        
        stats = analyze_pcap_file(pcap_file)
        
        # í†µê³„ ëˆ„ì 
        for key in total_stats:
            total_stats[key] += stats[key]
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ë¶„ì„ ì™„ë£Œ!")
    print("=" * 80)
    print(f"\nì²˜ë¦¬ëœ Flow í†µê³„:")
    print(f"  - ì „ì²´ (full): {total_stats['full']} flows")
    for window in PACKET_WINDOWS:
        print(f"  - ì²« {window}ê°œ íŒ¨í‚·: {total_stats[window]} flows")
    
    print(f"\nê²°ê³¼ ì €ì¥ ìœ„ì¹˜:")
    for window_name, folder in OUTPUT_FOLDERS.items():
        csv_count = len(list(folder.glob("*.csv")))
        print(f"  - {folder}: {csv_count}ê°œ CSV íŒŒì¼")
    
    print("\nâœ“ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


if __name__ == "__main__":
    main()
